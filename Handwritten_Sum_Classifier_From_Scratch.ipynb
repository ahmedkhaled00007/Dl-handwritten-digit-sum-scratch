{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a99b105",
   "metadata": {},
   "source": [
    "#  Handwritten Equation Sum Classifier (From Scratch)\n",
    "This notebook builds a deep neural network from scratch using NumPy to classify the **sum of two handwritten digits**.\n",
    "We use a synthetic dataset made by combining MNIST digit pairs and training a model to predict their sum (0–18)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fce4e4",
   "metadata": {},
   "source": [
    "##  Step 1: Load and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the MNIST dataset (28x28 grayscale images of digits 0–9)\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "\n",
    "# Normalize the pixel values to [0, 1] and convert labels to integers\n",
    "X_raw = mnist.data.to_numpy().astype(np.float32) / 255.0\n",
    "y_raw = mnist.target.to_numpy().astype(int)\n",
    "\n",
    "# Limit dataset to the first 60,000 samples (standard training split)\n",
    "X_raw = X_raw[:60000]\n",
    "y_raw = y_raw[:60000]\n",
    "\n",
    "# Prepare a new dataset of 30,000 images created by horizontally stacking two digits\n",
    "X_data, y_data = [], []\n",
    "for _ in range(30000):\n",
    "    # Randomly select two images from the first 2,000 samples\n",
    "    i1, i2 = np.random.randint(0, 2000, size=2)\n",
    "    \n",
    "    # Reshape the flattened 784-pixel images to 28x28\n",
    "    img1 = X_raw[i1].reshape(28, 28)\n",
    "    img2 = X_raw[i2].reshape(28, 28)\n",
    "    \n",
    "    # Combine them side by side (resulting in a 28x56 image)\n",
    "    combined = np.hstack([img1, img2])  \n",
    "    \n",
    "    # Flatten the combined image back to a 1D vector and store it\n",
    "    X_data.append(combined.flatten())\n",
    "    \n",
    "    # Label is the sum of the two digits (range: 0+0 to 9+9 → 0 to 18)\n",
    "    y_data.append(y_raw[i1] + y_raw[i2])\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_data = np.array(X_data)\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "# One-hot encode the labels (19 classes: 0 through 18)\n",
    "y_onehot = np.zeros((len(y_data), 19))\n",
    "for i, val in enumerate(y_data):\n",
    "    y_onehot[i, val] = 1  # Set the appropriate index to 1\n",
    "\n",
    "# Split the dataset into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_onehot, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99928f4c",
   "metadata": {},
   "source": [
    "##  Step 2: Visualize Some Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f467e795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first 5 combined digit images and their labels\n",
    "for i in range(5):\n",
    "    # Reshape the flattened vector back to a 28x56 image (two digits side by side)\n",
    "    img = X_data[i].reshape(28, 56)\n",
    "    \n",
    "    # Retrieve the label, which is the sum of the two digits in the image\n",
    "    label = y_data[i]\n",
    "    \n",
    "    # Display the image using grayscale colormap\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    # Set the title of the plot to show the sum of the two digits\n",
    "    plt.title(f\"Sum: {label}\")\n",
    "    \n",
    "    # Remove axis ticks and labels for a cleaner look\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7beace0",
   "metadata": {},
   "source": [
    "##  Step 3: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d713325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    ReLU activation function.\n",
    "\n",
    "    Parameters:\n",
    "    Z (np.ndarray): Input array (pre-activation values).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Output array where all negative values are set to 0, positive remain unchanged.\n",
    "    \"\"\"\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def relu_derivative(Z):\n",
    "    \"\"\"\n",
    "    Derivative of the ReLU function.\n",
    "\n",
    "    Parameters:\n",
    "    Z (np.ndarray): Input array (pre-activation values from forward pass).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Array of 0s and 1s. 1 where Z > 0, else 0.\n",
    "    \"\"\"\n",
    "    return (Z > 0).astype(float)\n",
    "\n",
    "def softmax(Z):\n",
    "    \"\"\"\n",
    "    Softmax activation function for multi-class classification.\n",
    "\n",
    "    Parameters:\n",
    "    Z (np.ndarray): Input 2D array (shape: classes x examples), raw scores (logits).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Probabilities for each class, normalized across classes for each example.\n",
    "    \"\"\"\n",
    "    exp_z = np.exp(Z - np.max(Z, axis=0, keepdims=True))  # Stability trick\n",
    "    return exp_z / np.sum(exp_z, axis=0, keepdims=True)\n",
    "\n",
    "def cross_entropy(y_hat, y_true):\n",
    "    \"\"\"\n",
    "    Cross-entropy loss for one-hot encoded labels.\n",
    "\n",
    "    Parameters:\n",
    "    y_hat (np.ndarray): Predicted probabilities (output of softmax), shape: (classes x examples).\n",
    "    y_true (np.ndarray): True one-hot encoded labels, same shape as y_hat.\n",
    "\n",
    "    Returns:\n",
    "    float: Cross-entropy loss (averaged over all examples).\n",
    "    \"\"\"\n",
    "    return -np.mean(np.sum(y_true * np.log(y_hat + 1e-8), axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a83722",
   "metadata": {},
   "source": [
    "##  Step 4: Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f9c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"\n",
    "    Initializes weights and biases for each layer in the neural network.\n",
    "\n",
    "    Parameters:\n",
    "    layer_dims (list): List of integers representing the number of units in each layer.\n",
    "                       For example, [input_dim, hidden1, hidden2, ..., output_dim]\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing initialized weights and biases:\n",
    "          - \"W1\", \"b1\", ..., \"WL\", \"bL\"\n",
    "          Weights are initialized using He initialization.\n",
    "    \"\"\"\n",
    "    parameters = {}  # Dictionary to store all parameters\n",
    "    for l in range(1, len(layer_dims)):\n",
    "        # He initialization for weights: good for ReLU activation\n",
    "        parameters[f\"W{l}\"] = np.random.randn(layer_dims[l], layer_dims[l-1]) * np.sqrt(2. / layer_dims[l-1])\n",
    "        # Initialize biases to zeros\n",
    "        parameters[f\"b{l}\"] = np.zeros((layer_dims[l], 1))\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def forward_prop(X, Y, parameters):\n",
    "    \"\"\"\n",
    "    Performs forward propagation through the network.\n",
    "\n",
    "    Parameters:\n",
    "    X (np.ndarray): Input data of shape (input_dim, number_of_examples).\n",
    "    Y (np.ndarray): True one-hot encoded labels of shape (num_classes, number_of_examples).\n",
    "    parameters (dict): Dictionary containing weights and biases for each layer.\n",
    "\n",
    "    Returns:\n",
    "    AL (np.ndarray): Final output (softmax probabilities), shape (num_classes, number_of_examples).\n",
    "    loss (float): Cross-entropy loss.\n",
    "    caches (list): List of cached values for each layer used in backpropagation.\n",
    "    \"\"\"\n",
    "    caches = []         # List to store intermediate results for backpropagation\n",
    "    A = X               # Initial activation is the input\n",
    "    L = len(parameters) // 2  # Number of layers (excluding input)\n",
    "\n",
    "    # Forward propagation through hidden layers\n",
    "    for l in range(1, L):\n",
    "        W, b = parameters[f\"W{l}\"], parameters[f\"b{l}\"]   # Get current layer weights and biases\n",
    "        Z = W @ A + b                                     # Linear forward step\n",
    "        A_prev = A                                        # Store previous activation for cache\n",
    "        A = relu(Z)                                       # Apply ReLU activation\n",
    "        caches.append((A_prev, Z, W, b))                  # Save cache for backprop\n",
    "\n",
    "    # Forward propagation through output layer\n",
    "    W, b = parameters[f\"W{L}\"], parameters[f\"b{L}\"]       # Final layer weights and biases\n",
    "    ZL = W @ A + b                                        # Linear step for output layer\n",
    "    AL = softmax(ZL)                                      # Apply softmax activation\n",
    "    caches.append((A, ZL, W, b))                          # Save final cache\n",
    "\n",
    "    loss = cross_entropy(AL, Y)                           # Compute cross-entropy loss\n",
    "    return AL, loss, caches\n",
    "\n",
    "\n",
    "def backward_prop(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Performs backward propagation to compute gradients.\n",
    "\n",
    "    Parameters:\n",
    "    AL (np.ndarray): Predicted output probabilities from forward pass (shape: classes x examples).\n",
    "    Y (np.ndarray): True one-hot encoded labels (same shape as AL).\n",
    "    caches (list): Cached values from forward propagation.\n",
    "\n",
    "    Returns:\n",
    "    grads (dict): Gradients of weights and biases:\n",
    "                  - \"dW1\", \"db1\", ..., \"dWL\", \"dbL\"\n",
    "    \"\"\"\n",
    "    grads = {}              # Dictionary to store gradients\n",
    "    m = Y.shape[1]          # Number of examples\n",
    "    L = len(caches)         # Number of layers\n",
    "\n",
    "    # Gradient of the loss w.r.t. softmax input (ZL)\n",
    "    A_prev, ZL, WL, bL = caches[-1]\n",
    "    dZL = AL - Y                                      # Derivative of softmax-crossentropy combo\n",
    "    grads[f\"dW{L}\"] = (1/m) * dZL @ A_prev.T          # Gradient of weights\n",
    "    grads[f\"db{L}\"] = (1/m) * np.sum(dZL, axis=1, keepdims=True)  # Gradient of biases\n",
    "    dA_prev = WL.T @ dZL                              # Backpropagate to previous activation\n",
    "\n",
    "    # Backprop through hidden layers\n",
    "    for l in reversed(range(1, L)):\n",
    "        A_prev, Z, W, b = caches[l-1]                 # Get cache values\n",
    "        dZ = dA_prev * relu_derivative(Z)             # Derivative through ReLU\n",
    "        grads[f\"dW{l}\"] = (1/m) * dZ @ A_prev.T        # Weight gradients\n",
    "        grads[f\"db{l}\"] = (1/m) * np.sum(dZ, axis=1, keepdims=True)  # Bias gradients\n",
    "        dA_prev = W.T @ dZ                             # Backpropagate to next layer\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Updates the network parameters using gradient descent.\n",
    "\n",
    "    Parameters:\n",
    "    parameters (dict): Current weights and biases.\n",
    "    grads (dict): Gradients of weights and biases from backward propagation.\n",
    "    learning_rate (float): Learning rate for gradient descent.\n",
    "\n",
    "    Returns:\n",
    "    dict: Updated parameters.\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2  # Number of layers\n",
    "    for l in range(1, L + 1):\n",
    "        # Update weights and biases using gradient descent\n",
    "        parameters[f\"W{l}\"] -= learning_rate * grads[f\"dW{l}\"]\n",
    "        parameters[f\"b{l}\"] -= learning_rate * grads[f\"db{l}\"]\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e9d225",
   "metadata": {},
   "source": [
    "##  Step 5: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b996640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, Y, layer_dims, learning_rate=0.1, iterations=2001, print_every=500):\n",
    "    \"\"\"\n",
    "    Trains a deep neural network using forward and backward propagation.\n",
    "\n",
    "    Parameters:\n",
    "    X (np.ndarray): Input data, shape (input_dim, number_of_examples).\n",
    "    Y (np.ndarray): One-hot encoded labels, shape (num_classes, number_of_examples).\n",
    "    layer_dims (list): List defining the number of neurons in each layer.\n",
    "                       Example: [input_dim, hidden1, hidden2, ..., output_dim]\n",
    "    learning_rate (float): Step size for updating parameters during gradient descent.\n",
    "    iterations (int): Number of training iterations (epochs).\n",
    "    print_every (int): Interval for printing the loss during training.\n",
    "\n",
    "    Returns:\n",
    "    parameters (dict): Trained weights and biases.\n",
    "    losses (list): List of loss values over iterations (for plotting or analysis).\n",
    "    \"\"\"\n",
    "    # Initialize weights and biases for all layers\n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    losses = []  # To store loss after each iteration\n",
    "\n",
    "    # Training loop\n",
    "    for i in range(iterations):\n",
    "        # Forward pass: compute predictions and loss\n",
    "        AL, loss, caches = forward_prop(X, Y, parameters)\n",
    "\n",
    "        # Backward pass: compute gradients\n",
    "        grads = backward_prop(AL, Y, caches)\n",
    "\n",
    "        # Update parameters using gradient descent\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "\n",
    "        # Record the loss for later analysis\n",
    "        losses.append(loss)\n",
    "\n",
    "        # Optionally print the loss at set intervals\n",
    "        if i % print_every == 0:\n",
    "            print(f\"Iteration {i}: Loss = {loss:.4f}\")\n",
    "\n",
    "    return parameters, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436bdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 3.0352\n",
      "Iteration 500: Loss = 0.8191\n",
      "Iteration 1000: Loss = 0.1094\n",
      "Iteration 1500: Loss = 0.0245\n",
      "Iteration 2000: Loss = 0.0103\n"
     ]
    }
   ],
   "source": [
    "# Transpose training data so that shape becomes (features, number_of_examples)\n",
    "# This matches the expected input shape for our neural network implementation\n",
    "X_train_T = X_train.T\n",
    "y_train_T = y_train.T\n",
    "\n",
    "# Define the architecture of the neural network\n",
    "# 1568 input neurons (28x56 images flattened)\n",
    "# 4 hidden layers: 512 → 256 → 128 → 64\n",
    "# 19 output neurons (summing digits: 0 to 18)\n",
    "layer_dims = [1568, 512, 256, 128, 64, 19]\n",
    "\n",
    "# Train the model using the train_model function\n",
    "# params will contain the trained weights and biases\n",
    "# loss_history will contain the loss value at each iteration\n",
    "params, loss_history = train_model(X_train_T, y_train_T, layer_dims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ae6c84",
   "metadata": {},
   "source": [
    "##  Step 6: Predict and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746f3a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 87.85%\n"
     ]
    }
   ],
   "source": [
    "def predict(X, parameters):\n",
    "    \"\"\"\n",
    "    Performs forward propagation and returns predicted class labels.\n",
    "\n",
    "    Parameters:\n",
    "    X (np.ndarray): Input data, shape (input_dim, number_of_examples).\n",
    "    parameters (dict): Trained weights and biases.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Predicted class labels (shape: number_of_examples,).\n",
    "    \"\"\"\n",
    "    A = X\n",
    "    L = len(parameters) // 2  # Number of layers\n",
    "\n",
    "    # Forward pass through hidden layers with ReLU\n",
    "    for l in range(1, L):\n",
    "        W, b = parameters[f\"W{l}\"], parameters[f\"b{l}\"]\n",
    "        Z = W @ A + b\n",
    "        A = relu(Z)\n",
    "\n",
    "    # Output layer (softmax)\n",
    "    W, b = parameters[f\"W{L}\"], parameters[f\"b{L}\"]\n",
    "    ZL = W @ A + b\n",
    "    probs = softmax(ZL)\n",
    "\n",
    "    # Return the index of the highest probability for each example\n",
    "    return np.argmax(probs, axis=0)\n",
    "\n",
    "\n",
    "# Transpose test data for compatibility: shape = (features, examples)\n",
    "preds = predict(X_test.T, params)\n",
    "\n",
    "# Convert one-hot encoded test labels to class indices\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(preds == true_labels)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d99390",
   "metadata": {},
   "source": [
    "## ✅ Conclusion\n",
    "This notebook demonstrated how to:\n",
    "- Build a deep neural network from scratch\n",
    "- Train it to recognize the **sum of two digits**\n",
    "- Evaluate performance with NumPy only\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
